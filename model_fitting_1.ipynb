{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fitting I\n",
    "\n",
    "We will first run a couple naive OLS fits, and then demonstrate why the approach is inappropriate in this context.\n",
    "\n",
    "### Naive OLS Fit\n",
    "\n",
    "The basic approach would be to use these data to fit a \"kitchen sink\" OLS regression. So lets see what these regressions would yield, and then address the plausibility of these results.\n",
    "\n",
    "*Note: We are using MacKinnon and White's (1985) HC3 heteroskedasticity robust covariance estimator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the libraries we will use and setting global options\n",
    "\n",
    "# Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action = \"ignore\")\n",
    "\n",
    "# Data manipulation and math/stats functions\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Plotting preferences\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import seaborn as sns\n",
    "\n",
    "# Import self-made functions\n",
    "from p3functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "student_both = pd.read_pickle('data/student_perf_v2.pkl') # both math and portuguese students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we fit our the OLS model let's clean up our dataset by converting strings to indicators and converting the final `G3` score into a percentage. We'll be using our make_indicator function located in p3functions.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'student_perf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6ca41d4cffc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Converting G3 to percent - the original paper specifies the range is {0, 20}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mstudent_both\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G3_perc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_perf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG3\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mstudent_both\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'studytime_continuous_sq'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_both\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'studytime_continuous'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'student_perf' is not defined"
     ]
    }
   ],
   "source": [
    "# Data formatting - converting categorical variables to indicators\n",
    "indicator_names = {\n",
    "    'course_por' : ('course', 'portuguese'),\n",
    "    'course_math' : ('course', 'mathematics'),\n",
    "    \n",
    "    'school_GP': ('school', 'GP'),\n",
    "    'male': ('sex', 'M'),\n",
    "    'urban': ('address', 'U'),\n",
    "    'fam_small': ('famsize', 'LE3'),\n",
    "    'fam_split': ('Pstatus', 'A'),\n",
    "    \n",
    "    'no_parent': ('guardian', 'other'),\n",
    "    'father': ('guardian', 'father'),\n",
    "    'mother': ('guardian', 'mother'),\n",
    "    \n",
    "    'school_sup': ('schoolsup', 'yes'),\n",
    "    'famsup': ('famsup', 'yes'),\n",
    "    'paid': ('paid', 'yes'),\n",
    "    'activities': ('activities', 'yes'),\n",
    "    'nursery': ('nursery', 'yes'),\n",
    "    'higher': ('higher', 'yes'),\n",
    "    'internet': ('internet', 'yes'),\n",
    "    'romantic': ('romantic', 'yes'),\n",
    "    \n",
    "    'Mjob_teach': ('Mjob', 'teacher'),\n",
    "    'Mjob_health': ('Mjob', 'health'),\n",
    "    'Mjob_civil': ('Mjob', 'services'),\n",
    "    'Mjob_other': ('Mjob', 'other'),\n",
    "    'Fjob_teach': ('Fjob', 'teacher'),\n",
    "    'Fjob_health': ('Fjob', 'health'),\n",
    "    'Fjob_civil': ('Fjob', 'services'),\n",
    "    'Fjob_other': ('Fjob', 'other'),\n",
    "    \n",
    "    'Medu_primary': ('Medu', 1),\n",
    "    'Medu_5_9': ('Medu', 2),\n",
    "    'Medu_secondary': ('Medu', 3),\n",
    "    'Medu_higher': ('Medu', 4),\n",
    "    'Fedu_primary': ('Fedu', 1),\n",
    "    'Fedu_5_9': ('Fedu', 2),\n",
    "    'Fedu_secondary': ('Fedu', 3),\n",
    "    'Fedu_higher': ('Fedu', 4),\n",
    "    \n",
    "    'reason_home' : ('reason', 'home'),\n",
    "    'reason_course' : ('reason', 'course'),\n",
    "    'reason_reputation' : ('reason', 'reputation'),\n",
    "    \n",
    "    'traveltime_0_15m' : ('traveltime', 1),\n",
    "    'traveltime_15_30m' : ('traveltime', 2),\n",
    "    'traveltime_30m_1h' : ('traveltime', 3),\n",
    "    'traveltime_1h_plus' : ('traveltime', 4),\n",
    "    \n",
    "    'famrel_1' : ('famrel', 1),\n",
    "    'famrel_2' : ('famrel', 2),\n",
    "    'famrel_3' : ('famrel', 3),\n",
    "    'famrel_4' : ('famrel', 4),\n",
    "    'famrel_5' : ('famrel', 5),\n",
    "    \n",
    "    'freetime_1' : ('freetime', 1),\n",
    "    'freetime_2' : ('freetime', 2),\n",
    "    'freetime_3' : ('freetime', 3),\n",
    "    'freetime_4' : ('freetime', 4),\n",
    "    'freetime_5' : ('freetime', 5),\n",
    "    \n",
    "    'goout_1' : ('goout', 1),\n",
    "    'goout_2' : ('goout', 2),\n",
    "    'goout_3' : ('goout', 3),\n",
    "    'goout_4' : ('goout', 4),\n",
    "    'goout_5' : ('goout', 5),\n",
    "\n",
    "    'Dalc_1' : ('Dalc', 1),\n",
    "    'Dalc_2' : ('Dalc', 2),\n",
    "    'Dalc_3' : ('Dalc', 3),\n",
    "    'Dalc_4' : ('Dalc', 4),\n",
    "    'Dalc_5' : ('Dalc', 5),\n",
    "\n",
    "    'Walc_1' : ('Walc', 1),\n",
    "    'Walc_2' : ('Walc', 2),\n",
    "    'Walc_3' : ('Walc', 3),\n",
    "    'Walc_4' : ('Walc', 4),\n",
    "    'Walc_5' : ('Walc', 5),\n",
    "\n",
    "    'health_1' : ('health', 1),\n",
    "    'health_2' : ('health', 2),\n",
    "    'health_3' : ('health', 3),\n",
    "    'health_4' : ('health', 4),\n",
    "    'health_5' : ('health', 5)\n",
    "}\n",
    "make_indicators(student_both, indicator_names)\n",
    "\n",
    "# Converting G3 to percent - the original paper specifies the range is {0, 20}\n",
    "student_both['G3_perc'] = student_perf.G3 / 20\n",
    "student_both['studytime_continuous_sq'] = student_both['studytime_continuous']**2\n",
    "\n",
    "# Splitting into individual courses\n",
    "student_por  = student_both.loc[student_both['course_por'] == 1]   # Portuguese language course students\n",
    "student_mat  = student_both.loc[student_both['course_math'] == 1]  # Mathematics course students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### School Level Controls - Model Fitting\n",
    "\n",
    "For our first models we do not control for individual level characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the OLS model with discrete mapping, only school level controls\n",
    "## Note: we leave out the first group from `studytime` for collinearity purposes\n",
    "\n",
    "# Both Courses\n",
    "Y_both = student_both.G3_perc\n",
    "X_both = student_both[['studytime_dscr2', 'studytime_dscr3', 'studytime_dscr4', \n",
    "                      'school_GP', 'course_math']]\n",
    "X_both = sm.add_constant(X_both)\n",
    "results1_disc_both = sm.OLS(Y_both, X_both).fit(cov_type='HC3')\n",
    "\n",
    "# Portuguese Language Course\n",
    "Y_por = student_por.G3_perc\n",
    "X_por = student_por[['studytime_dscr2', 'studytime_dscr3', 'studytime_dscr4', \n",
    "                      'school_GP']]\n",
    "X_por = sm.add_constant(X_por)\n",
    "results1_disc_por = sm.OLS(Y_por, X_por).fit(cov_type='HC3')\n",
    "\n",
    "# Portuguese Language Course\n",
    "Y_mat = student_mat.G3_perc\n",
    "X_mat = student_mat[['studytime_dscr2', 'studytime_dscr3', 'studytime_dscr4', \n",
    "                      'school_GP']]\n",
    "X_mat = sm.add_constant(X_mat)\n",
    "results1_disc_mat = sm.OLS(Y_mat, X_mat).fit(cov_type='HC3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the OLS model with continuous mapping, only school level controls\n",
    "## Note: we leave out the first group from `studytime` for collinearity purposes\n",
    "\n",
    "# Both Courses\n",
    "Y_both = student_both.G3_perc\n",
    "X_both = student_both[['studytime_continuous', 'studytime_continuous_sq', \n",
    "                      'school_GP', 'course_math']]\n",
    "X_both = sm.add_constant(X_both)\n",
    "results1_cont_both = sm.OLS(Y_both, X_both).fit(cov_type='HC3')\n",
    "\n",
    "# Portuguese Language Course\n",
    "Y_por = student_por.G3_perc\n",
    "X_por = student_por[['studytime_continuous', 'studytime_continuous_sq', \n",
    "                      'school_GP']]\n",
    "X_por = sm.add_constant(X_por)\n",
    "results1_cont_por = sm.OLS(Y_por, X_por).fit(cov_type='HC3')\n",
    "\n",
    "# Portuguese Language Course\n",
    "Y_mat = student_mat.G3_perc\n",
    "X_mat = student_mat[['studytime_continuous', 'studytime_continuous_sq', \n",
    "                      'school_GP']]\n",
    "X_mat = sm.add_constant(X_mat)\n",
    "results1_cont_mat = sm.OLS(Y_mat, X_mat).fit(cov_type='HC3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Level Controls - Model Fitting\n",
    "\n",
    "For our second models we include controls for individual level characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the full OLS model with discrete mapping\n",
    "## Note: we leave out the first group from `studytime` for collinearity purposes\n",
    "\n",
    "covar_names = ['studytime_dscr2', 'studytime_dscr3', 'studytime_dscr4', \n",
    "               'school_GP', 'course_math', 'male', 'age', 'urban', 'fam_small', 'fam_split', \n",
    "               'mother', 'father', 'failures', 'school_sup', 'famsup', 'paid', \n",
    "               'activities', 'nursery', 'higher', 'internet', 'romantic', 'absences',\n",
    "               'Mjob_teach', 'Mjob_health', 'Mjob_civil', 'Mjob_other', \n",
    "               'Fjob_teach', 'Fjob_health', 'Fjob_civil', 'Fjob_other',\n",
    "               'Medu_primary', 'Medu_5_9', 'Medu_secondary', 'Medu_higher', \n",
    "               'Fedu_primary', 'Fedu_5_9', 'Fedu_secondary', 'Fedu_higher', \n",
    "               'reason_home', 'reason_course', 'reason_reputation',\n",
    "               'traveltime_15_30m', 'traveltime_30m_1h', 'traveltime_1h_plus',\n",
    "               'famrel_1', 'famrel_2', 'famrel_4', 'famrel_5',\n",
    "               'freetime_1', 'freetime_2', 'freetime_4', 'freetime_5',\n",
    "               'goout_1', 'goout_2', 'goout_4', 'goout_5',\n",
    "               'Dalc_1', 'Dalc_2', 'Dalc_4', 'Dalc_5',\n",
    "               'Walc_1', 'Walc_2', 'Walc_4', 'Walc_5',\n",
    "               'health_1', 'health_2', 'health_4', 'health_5']\n",
    "\n",
    "# Both Courses\n",
    "Y_both = student_both.G3_perc\n",
    "X_both = student_both[covar_names]\n",
    "X_both = sm.add_constant(X_both)\n",
    "results2_disc_both = sm.OLS(Y_both, X_both).fit(cov_type='HC3')\n",
    "\n",
    "# Portuguese Language Course\n",
    "Y_por = student_por.G3_perc\n",
    "X_por = student_por[covar_names]\n",
    "X_por = sm.add_constant(X_por)\n",
    "results2_disc_por = sm.OLS(Y_por, X_por).fit(cov_type='HC3')\n",
    "\n",
    "# Mathematics Course\n",
    "Y_mat = student_mat.G3_perc\n",
    "X_mat = student_mat[covar_names]\n",
    "X_mat = sm.add_constant(X_mat)\n",
    "results2_disc_mat = sm.OLS(Y_mat, X_mat).fit(cov_type='HC3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the OLS model with continuous mapping\n",
    "\n",
    "covar_names = ['studytime_continuous', 'studytime_continuous_sq', \n",
    "               'school_GP', 'course_math', 'male', 'age', 'urban', 'fam_small', 'fam_split', \n",
    "               'mother', 'father', 'failures', 'school_sup', 'famsup', 'paid', \n",
    "               'activities', 'nursery', 'higher', 'internet', 'romantic', 'absences',\n",
    "               'Mjob_teach', 'Mjob_health', 'Mjob_civil', 'Mjob_other', \n",
    "               'Fjob_teach', 'Fjob_health', 'Fjob_civil', 'Fjob_other',\n",
    "               'Medu_primary', 'Medu_5_9', 'Medu_secondary', 'Medu_higher', \n",
    "               'Fedu_primary', 'Fedu_5_9', 'Fedu_secondary', 'Fedu_higher', \n",
    "               'reason_home', 'reason_course', 'reason_reputation',\n",
    "               'traveltime_15_30m', 'traveltime_30m_1h', 'traveltime_1h_plus',\n",
    "               'famrel_1', 'famrel_2', 'famrel_4', 'famrel_5',\n",
    "               'freetime_1', 'freetime_2', 'freetime_4', 'freetime_5',\n",
    "               'goout_1', 'goout_2', 'goout_4', 'goout_5',\n",
    "               'Dalc_1', 'Dalc_2', 'Dalc_4', 'Dalc_5',\n",
    "               'Walc_1', 'Walc_2', 'Walc_4', 'Walc_5',\n",
    "               'health_1', 'health_2', 'health_4', 'health_5']\n",
    "\n",
    "# Both Courses\n",
    "Y_both = student_both.G3_perc\n",
    "X_both = student_both[covar_names]\n",
    "X_both = sm.add_constant(X_both)\n",
    "results2_cont_both = sm.OLS(Y_both, X_both).fit(cov_type='HC3')\n",
    "\n",
    "# Portuguese Language Course\n",
    "Y_por = student_por.G3_perc\n",
    "X_por = student_por[covar_names]\n",
    "X_por = sm.add_constant(X_por)\n",
    "results2_cont_por = sm.OLS(Y_por, X_por).fit(cov_type='HC3')\n",
    "\n",
    "# Mathematics Course\n",
    "Y_mat = student_mat.G3_perc\n",
    "X_mat = student_mat[covar_names]\n",
    "X_mat = sm.add_constant(X_mat)\n",
    "results2_cont_mat = sm.OLS(Y_mat, X_mat).fit(cov_type='HC3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Results - Discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_col([results1_disc_both, results1_disc_por, results1_disc_mat, \n",
    "                   results2_disc_both, results2_disc_por, results2_disc_mat], \n",
    "                  stars=True, float_format='%0.4f',\n",
    "                  model_names=['Both\\n(School\\nControls)','Portuguese\\n(School\\nControls)','Mathematics\\n(School\\nControls)', \n",
    "                               'Both\\n(Individual\\nControls)','Portuguese\\n(Individual\\nControls)','Mathematics\\n(Individual\\nControls)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)), \n",
    "                             'Df': lambda x: \"{0:d}\".format(int(x.df_model)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared),\n",
    "                             'Adj-R2':lambda x: \"{:.2f}\".format(x.rsquared_adj),\n",
    "                             'F-Stat':lambda x: \"{:.2f}\".format(float(x.fvalue)),\n",
    "                             'F-Stat-prob':lambda x: \"{:.2f}\".format(x.f_pvalue)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Results - Continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_col([results1_cont_both, results1_cont_por, results1_cont_mat, \n",
    "                   results2_cont_both, results2_cont_por, results2_cont_mat], \n",
    "                  stars=True, float_format='%0.4f',\n",
    "                  model_names=['Both\\n(School\\nControls)','Portuguese\\n(School\\nControls)','Mathematics\\n(School\\nControls)', \n",
    "                               'Both\\n(Individual\\nControls)','Portuguese\\n(Individual\\nControls)','Mathematics\\n(Individual\\nControls)'],\n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)),  \n",
    "                             'Df': lambda x: \"{0:d}\".format(int(x.df_model)),\n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared),\n",
    "                             'Adj-R2':lambda x: \"{:.2f}\".format(x.rsquared_adj),\n",
    "                             'F-Stat':lambda x: \"{:.2f}\".format(float(x.fvalue)),\n",
    "                             'F-Stat-prob':lambda x: \"{:.2f}\".format(x.f_pvalue)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression Output Table Reproducibility Note:\n",
    "\n",
    "Example of how I transfer results from the notebook to the .tex file.\n",
    "\n",
    "```python\n",
    "print(summary_col([results1_cont_both, results1_cont_por, results1_cont_mat, \n",
    "                   results2_cont_both, results2_cont_por, results2_cont_mat], \n",
    "                  stars=True, float_format='%0.4f', \n",
    "                  info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs)), \n",
    "                             'R2':lambda x: \"{:.2f}\".format(x.rsquared),\n",
    "                             'Adj-R2':lambda x: \"{:.2f}\".format(x.rsquared_adj),\n",
    "                             'F-Stat':lambda x: \"{:.2f}\".format(float(x.fvalue)),\n",
    "                             'F-Stat-prob':lambda x: \"{:.2f}\".format(x.f_pvalue)}\n",
    "                 ).as_latex())\n",
    "```\n",
    "\n",
    "This outputs the above table in .tex readable format. I then copy the lines we want to report and paste them into a table format in the .tex document. Additional formatting is then done to make sure the tables look nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving our cleaned dataset and results of our Naive OLS fit\n",
    "student_both.to_pickle('data/student_both_v3.pkl')\n",
    "student_por.to_pickle('data/student_por_v3.pkl')\n",
    "student_mat.to_pickle('data/student_mat_v3.pkl')\n",
    "\n",
    "results1_disc_both.save('results/Naive_OLS1_disc_both.pickle')\n",
    "results1_disc_por.save('results/Naive_OLS1_disc_por.pickle')\n",
    "results1_disc_mat.save('results/Naive_OLS1_disc_mat.pickle')\n",
    "results2_disc_both.save('results/Naive_OLS2_disc_both.pickle')\n",
    "results2_disc_por.save('results/Naive_OLS2_disc_por.pickle')\n",
    "results2_disc_mat.save('results/Naive_OLS2_disc_mat.pickle')\n",
    "\n",
    "results1_cont_both.save('results/Naive_OLS1_cont_both.pickle')\n",
    "results1_cont_por.save('results/Naive_OLS1_cont_por.pickle')\n",
    "results1_cont_mat.save('results/Naive_OLS1_cont_mat.pickle')\n",
    "results2_cont_both.save('results/Naive_OLS2_cont_both.pickle')\n",
    "results2_cont_por.save('results/Naive_OLS2_cont_por.pickle')\n",
    "results2_cont_mat.save('results/Naive_OLS2_cont_mat.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity\n",
    "\n",
    "We might be interesting in testing the multicollinearity in our model. Below we compute the variance inflation factor of our final model (continuous studytime mapping) and report the most collinear variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the Variance Inflation Factor\n",
    "vif = pd.DataFrame({\n",
    "    'Feature' : X_both.columns,\n",
    "    'VIF Factor' : [variance_inflation_factor(X_both.values, i) for i in range(X_both.shape[1])]\n",
    "})\n",
    "\n",
    "# Displaying the first 10 sorted VIF's after dropping the VIF for the intercept\n",
    "vif.iloc[1:].sort_values(by = 'VIF Factor', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that VIF suggests that there is some multicollinearity between parents' levels of education. The collinearity does not seem too extreme however, and we will keep these variables as regressors in our later models as they are usually considered good proxies for the unobserved ability. Additionally it is plausible that parents with higher educations will pressure their children to study more. If this were the case then studying time would covary with parental education, so omitting parental education would cause studying time to be endogenous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Variable Selection\n",
    "\n",
    "We may be interested in a dimension reduction technique that tells us which variables are most important in prediction of our dependent variable. For our LASSO-flavor regularized variable selection exploration, we need to first standardize the data (recall that the LASSO results are not scale invariant). Note that we also remove the intercept from the design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the design matrix\n",
    "Y = Y_both; X = X_both\n",
    "stand_X = (X.iloc[:,1:] - X.iloc[:,1:].mean())/X.iloc[:,1:].std()\n",
    "stand_Y = (Y - Y.mean())/Y.std()\n",
    "\n",
    "# Fitting the model\n",
    "clf = linear_model.Lasso(alpha = 0.1)\n",
    "test = clf.fit(stand_X, stand_Y)\n",
    "\n",
    "# Returning data frame of non-zero coefficients after penalization\n",
    "penalized_results = pd.DataFrame({\n",
    "    'Feature' : stand_X.columns, \n",
    "    'Regularized Coeff.' : test.coef_\n",
    "})\n",
    "\n",
    "penalized_results[penalized_results['Regularized Coeff.'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that a LASSO flavor penalization only assigns high importance to weekly studytime, the school, the course of study, the number of failures, whether the student wants to take higher education, whether the mother had higher education, and whether the student is in the lowest bin of weekly alcohol consumption.  \n",
    "It is very reassuring that our continuous mapping of weekly studying time is not shrunk to zero. The importance of school was covered previously, and this result supports the inclusion of school in even the most basic models. Inclusion of `higher` makes intuitive sense, students who are interested in college would necessarily be more motivated to do well on tests. Inclusion of the indicator for mothers who had higher education supports our decision to include parental education despite the collinearity. Interestingly, only the indicator for the lowest bin of weekly alcohol consumption in not shrunk to zero - this may have the same intution as inclusion of `higher`, perhaps there is some background decision process in which students who care about grades are also drinking less.\n",
    "\n",
    "*Note: We select a penalization parameter $\\alpha$ so that we shrink all but seven of the coefficients to zero. If we select different values for $\\alpha$ then we would include more or less coefficients as non zero.  \n",
    "We chose to shrink to seven non zero coefficients because if we shrink further then studying time is shrunk to zero - while this practice is a bit sneaky, we feel that since we are not using these results for more than our own intuition, it is allowable. This exploration was meant more for our own curiosity rather than any reported results.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW HERE IS OLD STUFF -  IGNORE\n",
    "can use some of the structure and plotting in `model_fitting_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quadratic2SLS as q2sls\n",
    "import importlib\n",
    "importlib.reload(q2sls)\n",
    "\n",
    "Y = student_por.G3_perc\n",
    "X = student_por[['school_GP', 'male', 'age', 'urban', 'fam_small', 'fam_split', \n",
    "                  'mother', 'father', 'failures', 'school_sup', 'famsup', 'paid', \n",
    "                  'activities', 'nursery', 'higher', 'internet', 'romantic', 'absences',\n",
    "                  'Mjob_teach', 'Mjob_health', 'Mjob_civil', 'Mjob_other', \n",
    "                  'Fjob_teach', 'Fjob_health', 'Fjob_civil', 'Fjob_other',\n",
    "                  'Medu_primary', 'Medu_5_9', 'Medu_secondary', 'Medu_higher', \n",
    "                  'Fedu_primary', 'Fedu_5_9', 'Fedu_secondary', 'Fedu_higher', \n",
    "                  'famrel_1', 'famrel_2', 'famrel_4', 'famrel_5',\n",
    "                  'freetime_1', 'freetime_2', 'freetime_4', 'freetime_5',\n",
    "                  'Dalc_1', 'Dalc_2', 'Dalc_4', 'Dalc_5',\n",
    "                  'Walc_1', 'Walc_2', 'Walc_4', 'Walc_5',\n",
    "                  'health_1', 'health_2', 'health_4', 'health_5']]\n",
    "X = sm.add_constant(X)\n",
    "X_endog = student_por['studytime_continuous']\n",
    "student_por['artificial_instrument'] = ((student_por.reason == 'home') & (student_por.traveltime > 1)).astype(int)\n",
    "Z = student_por[['artificial_instrument',\n",
    "                  'goout_1', 'goout_2', 'goout_4', 'goout_5']]\n",
    "\n",
    "model = q2sls.Quadratic2SLS(Y, X, X_endog, Z)\n",
    "result_20000 = model.fit(cov_type='Bootstrap', n_iter=1000)\n",
    "coeff_estms_20000 = pd.DataFrame([result_20000.beta_hat_boots.mean(axis=0), result_20000.result2.params]).transpose()\n",
    "coeff_estms_20000.columns = ['Bootstrapped', 'Full_Sample']\n",
    "coeff_estms_20000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the plots\n",
    "plt.figure(figsize=(16, 36))\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "plt.subplots_adjust(top=0.97)\n",
    "plt.suptitle('Bootstrapped Coefficient Estimates Compared to Full Sample Estimate')\n",
    "\n",
    "sns.despine()\n",
    "for column_index, column in enumerate(result_20000.X_hat.columns.values.tolist()):\n",
    "    plt.subplot(19, 3, column_index + 1)\n",
    "    sns.kdeplot(result_20000.beta_hat_boots[column])\n",
    "    plt.plot([result_20000.result2.params[column_index], result_20000.result2.params[column_index]], \n",
    "             [0, 500], \n",
    "             linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:\n",
    "### At first it kind of looked like only the continuous variables were being biased, but looking closer there is also bias in the binary vars. its just that a couple of them are centered around the full sample estimates. I suppose it is possible that 20,000 is too few iterations, but that seems unlikely with a sample of 650.\n",
    "### Also, see the graph below, the coeff. estimates stabalize pretty quickly\n",
    "\n",
    "Could this be an artifact of small sample bias? It is known that 2SLS suffers from small sample bias [LINK](http://econ.lse.ac.uk/staff/spischke/ec533/Weak%20IV.pdf), but in the setting of bootstrapping, each sample is the same size, it just has repeated observations. Could this be causing bias in a funky way that's related to small sample bias? Would we expect the bias to be oddly focused on specific variables? Need to think about this more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability of coeff on endog_hat in bootstrapping\n",
    "cumsum_beta_hat_boots = np.cumsum(result_20000.beta_hat_boots['endog_hat'])\n",
    "sns.tsplot(cumsum_beta_hat_boots/np.arange(20000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quadratic2SLS as q2sls\n",
    "import importlib\n",
    "importlib.reload(q2sls)\n",
    "\n",
    "Y = student_perf.G3_perc\n",
    "X = student_perf[['school_GP', 'course_math', 'male', 'age', 'urban', 'fam_small', 'fam_split', \n",
    "                  'mother', 'father', 'failures', 'school_sup', 'famsup', 'paid', \n",
    "                  'activities', 'nursery', 'higher', 'internet', 'romantic', 'absences',\n",
    "                  'Mjob_teach', 'Mjob_health', 'Mjob_civil', 'Mjob_other', \n",
    "                  'Fjob_teach', 'Fjob_health', 'Fjob_civil', 'Fjob_other',\n",
    "                  'Medu_primary', 'Medu_5_9', 'Medu_secondary', 'Medu_higher', \n",
    "                  'Fedu_primary', 'Fedu_5_9', 'Fedu_secondary', 'Fedu_higher', \n",
    "                  'famrel_1', 'famrel_2', 'famrel_4', 'famrel_5',\n",
    "                  'freetime_1', 'freetime_2', 'freetime_4', 'freetime_5',\n",
    "                  'Dalc_1', 'Dalc_2', 'Dalc_4', 'Dalc_5',\n",
    "                  'Walc_1', 'Walc_2', 'Walc_4', 'Walc_5',\n",
    "                  'health_1', 'health_2', 'health_4', 'health_5']]\n",
    "X = sm.add_constant(X)\n",
    "X_endog = student_perf['studytime_continuous']\n",
    "student_perf['artificial_instrument'] = 1*(student_perf.reason == 'home')*1*(student_perf.traveltime > 1)\n",
    "Z = student_perf[['artificial_instrument',\n",
    "                  'goout_1', 'goout_2', 'goout_4', 'goout_5']]\n",
    "\n",
    "np.random.seed(1234)\n",
    "model = q2sls. Quadratic2SLS(Y, X, X_endog, Z, X, Z)\n",
    "#result = model.fit(cov_type='Bootstrap', n_iter = 50000)\n",
    "result = model.fit(cov_type='Bootstrap', n_iter = 1000)\n",
    "coeff_estms = pd.DataFrame([result.beta_hat_boots.mean(axis=0), result.result2.params]).transpose()\n",
    "coeff_estms.columns = ['Bootstrapped', 'Full_Sample']\n",
    "coeff_estms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stability of coeff on endog_hat in bootstrapping\n",
    "cumsum_beta_hat_boots = np.cumsum(result.beta_hat_boots['endog_hat'])\n",
    "sns.tsplot(cumsum_beta_hat_boots/np.array(list(range(0, model.n_iter))));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM!!!\n",
    "### seems like there still might be a problem with the bootstrapping estimates. the estimated coefficient in bootstrapping never gets even close to the estimated coefficient in the full sample. i already tested whether it was the order of indicies, and fixed that issue, but maybe there is a seperate problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.iv import IV2SLS \n",
    "model = IV2SLS(Y, X, X_endog, Z)\n",
    "results = model.fit()\n",
    "print(results.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
